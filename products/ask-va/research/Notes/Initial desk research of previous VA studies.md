# Initial desk research of previous VA studies
Last updated by @tygindraux on June 8, 2023

## Overview of studies in chronological order
* [Profile Notification Settings, Add Email Channel - January 2023](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#profile-notification-settings-add-email-channel)
* [Disabled Veteran Accessibility Feedback - 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#disabled-veteran-accessibility-feedback)
* [MCT Chatbot as AVA Front Door - Dec 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#multi-channel-technologies-mct-chatbot-as-ava-front-door)
* [MCT Virtual Agent Chatbot Login.Gov and ID.me Moderated Interviews - Dec 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#mct-virtual-agent-chatbot-logingov-and-idme-moderated-interviews)
* [Chatbot Feature Prioritization - August 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#chatbot-feature-prioritization)
* [MCT Omnichannel Experience: Co-Design Phase II - June 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#mct-omnichannel-experience-co-design-phase-ii) 
* [VA Orchid, Virtual Agent Chatbot - June 14, 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#va-orchid-virtual-agent-chatbot)
* [MCT VHA Virtual Agent Research - June 24, 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#mct-vha-virtual-agent-research)
* [MCT Omnichannel Experience: Co-Design - March 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#mct-omnichannel-experience-co-design)
* [Virtual Agent Authentication Usability Test - March 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#virtual-agent-authentication-usability-test)
* [VSP, Ask VA - Dashboard (Business, Personal) - January 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#vsp-ask-va---dashboard-business-personal)
* [Needs of Spanish Speaking Veterans for the Virtual Agent - January 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#needs-of-spanish-speaking-veterans-for-the-virtual-agent)
* [MCT Virtual Agent Facilities Conversational Design - January 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#mct-virtual-agent-facilities-conversational-design)
* [Virtual Agent Automated Content and Claims Feature Usability Testing - Nov 2021](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#virtual-agent-automated-content-and-claims-feature-usability-testing)
* [VSP, Ask VA - July 2021](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#vsp-ask-va)
* [Virtual Agent Inclusive Design interviews - June 2021](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#virtual-agent-inclusive-design-interviews)
* [Ask VA - April 2021](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#ask-va)
* [VA.gov Relaunch - 2018](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#vagov-relaunch)

## Studies related to Ask VA, chatbot, virtual agent or other support tools

### Disabled Veteran Accessibility Feedback

|Issue|Not available. [Link to findings document](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/teams/shared-support/accessibility/research/2022-feedback/a11y-feedback-research-findings.md).|
|:--|:--|
|Date|2022|
|Team|Josh Kim, A11y|
|Background|Our goal is to establish a process to collect a11y feedback from the public. In order to accomplish this goal, we need to (1) determine whether disabled Veterans are providing feedback through existing feedback mechanisms (and if not, why not?), and (2) start to gain preliminary insight or determine next steps on how to gain insights into disabled Veteran's behaviors, feelings, perspectives, and expectations on providing a11y feedback.|

#### Objectives
* How accessible (and to a degree usable) are current feedback methods on VA.gov?
* Where do disabled Veterans currently provide or expect to be able to provide a11y feedback on VA.gov (if at all)?
* What are all the current existing mechanisms (accessible or not)?
* What kind of a11y feedback do disabled Veterans provide (or want to provide) on VA.gov?
* Do some subgroups (or individuals) among disabled Veterans have a greater need (if at all) for providing and resolving accessibility feedback more than others?
* How is a11y feedback for VA.gov currently processed?
* What mental models do disabled Veterans have of the a11y feedback process on VA.gov?
#### Findings
* Contact Center surveys
  * The majority of the data we parsed through was noise, with little key signals that could answer or relate to our research questions
  * Out of 4000+ lines of potential keyword matches, we were only able to extract ~10-20 lines of potentially relevant feedback, but they were either too broad, were inspecific, or lacked context to extract any confidence from
  * This could be a symptom of the inaccessibility or discoverability of the feedback button and feedback survey for disabled Veterans, and may be a topic for future research
* Page analytics
  * Between January 1 and November 17, 2022, the accessibility link in the footer of modernized va.gov pages was clicked 26,005.
  * Of those clicks, 18,123 of them were triggered from a mobile device.
  * The 508 page received 56,290 page views, this means that about 46% of all traffic to the 508 accessibility page came through the footer link.
  * This data was analyzed at a very preliminary level; there is an opportunity to do a deeper analysis with a more longitudinal set of data.
  * We have determined that there is traffic from the footer to the 508 page – a follow up analysis should be done to determine why folks are going to the 508 page and if they are able to find what they are looking for there.
* Accessibility audits 
  * All of the methods of providing feedback to VA.gov that we audited have confirmed major accessibility issues which may prevent disabled people from submitting accessibility feedback.
  * 2 of the methods we audited have confirmed severe major accessibility issues which likely completely bars access to providing feedback.
  * Many of these methods were audited in the past based on Section 508 standards (as opposed to WCAG 2.1 AA) which does not cover responsive, mobile, and cognitive considerations).  Maintenance historically has not often been conducted post-audit, even with the introduction of updated standards.
  * They will likely not capture all potential accessibility or usability issues for disabled Veterans. We should consider the existence of issues as a sign that further testing and usability testing with disabled Veterans should be strongly considered.
  * WCAG 2.1+ (not 508) accessibility audits and usability testing with disabled Veterans using a variety of assistive technology should be conducted for methods we still don’t have access to (or are unaware of) including the IVR survey, facility QR codes, email, and more.
  * More research is needed to understand the disabled Veteran experience of calling My VA 411 as it is currently the only known usable method for disabled Veterans to provide accessibility feedback beyond the Section 508 email.
* Appended interview questions with Veterans
  * One participant did not know how to provide feedback, one would look for a "contact us" area, one would attempt to call the VA, and another would self-advocate through the Blinded Veterans Association (BVA)
  * Going to a physical location, like a VAMC, was a common fallback should preferred methods not work for 4 out of the 6 participants
  * Screen magnification users on desktop (2/2 in total) didn’t notice the VA.gov feedback button. This is likely due to screen magnification showing only part of the screen at any given time. As there’s no indication that the feedback exists on the bottom right side of the page, it may be missed by magnification users who scan the page left to right with a limited view. For example, consider the simulated image below.
  * Given these were appended onto interviews with different facilitators, the manner in which questions were posed were inconsistent. As such, the above insights should be interpreted as a strong call to do more research instead of a factual or permanent representation of all disabled Veterans.
  * This research only covered the needs of Veterans with low vision or blindness with zoomtext and screen readers; it does not address the needs of Veterans using other types of assistive technologies
* Contact Center Panel Interview
  * Ask.va.gov receives a11y tickets from folks communicating on behalf of someone else. It’s likely inaccessible as it doesn’t follow the VA design system and Aubrey’s team’s recommendations were unresolved due to platform limitations with the dynamic 365 portal. It was likely not tested for Section 508 compliance.
  * Medallia feedback button and intercept survey were tested last year, but screen reader users did not participate despite Ian making a request to Perigean. This may be easier this year with new partnerships with blinded Veteran organizations.
  * The primary call center is My VA 411 (800-698-2411). There’s also a White House national hotline. When a Veteran calls the number and reaches an operator, they’ve reached tier 1 support. If their issue cannot be resolved, it is escalated to tier 2 which is the contact center team. If it cannot be resolved there, it becomes tier 3 which is often for technical issues like editing the markup of the website.
    * We’re not sure how the TTY number is handled nor how accessibility issues are triaged.
    * Tier 1 agents can log calls in salesforce, but the interface is difficult to search. Many issues found within salesforce at a glance appear to be home related accessibility issues (as opposed to digital website issues).
    * There’s a possibility a11y feedback may stop at a tier 1 agent as the surface level problem may be addressed over call (reading out a data table) while still leaving the source of the issue unresolved (the data table itself is still inaccessible).
  * Medallia feedback has not yet been tested with disabled Veterans using assistive technology. Previous usability testing focused on (1) the initial feedback button and (2) an updated version of that feedback button which demonstrated significant usability improvements for able-bodied Veterans. Conducting research in the future with assistive tech users may unveil key usability insights related to more complex cases and lead to data-driven inclusive enhancements.
* Mike Manalo Interview
  * No interviews were conducted with disabled Veterans using assistive technology. This was due to Perigean wanting more specific guidance on what “assistive technology” meant. In this case, they got older Veterans using iPads (as opposed to technologies explicitly used for a disability like a screen reader or keyboard).
  * The more complex the issue, the more likely Veterans will call. There were forming patterns of older Veterans being associated with doctor appointments and facilities which could generally be resolved via tier 1 support, but any issue requiring more complex topics like verifying a GI Bill payment often went to tier 2 support. There’s an open question of what is effective communication: SMS? Phone? Etc?
  * Unsure if there are any particular groups using or not using 411. Salesforce may help answer that. The vast majority of issues are related to authentication. The contact center team is creating a service map of how tier 1 issues are escalated to tier 2, how long those issues sit, and how they are resolved.
* Section 508 office
  * VA.gov team to draft modernized accessibility statement. Team acknowledged that the Section 508 page was 15 years old and that a modernized accessibility statement in Veteran-facing plain language would be a welcome improvement in hopes of gathering more feedback through the Section 508 email address.
  * Veterans are frustrated they don’t hear back when they provide feedback. “Biggest complaint from peers is when they do complain they don’t ever hear anything. So someone needs to respond with details so they know they’re heard. Veterans feel like they complained but I never heard anything. So why should I mess with it.”
  * Managing who tickets go to and how they’re resolved is a complex process. When the Section 508 office receives feedback from Veterans through their email, they first determine if it is (or isn’t) an issue they can address. If they can address it, they create a servicenow ticket for their team. If they can’t, they find the appropriate team to forward it to. A pain point here is that when they forward tickets, there’s no guarantee the team it is forwarded to will provide a response back confirming a fix. Even if they do, it’s often too late for the Veteran who may have to sit on an unresolved issue for 6+ weeks.
  * Section 508 office is interested in the potential of ask.va.gov, but haven’t been included yet. The office is looking for a way to reduce the number of feedback ticketing systems and looking into ways to follow up on tickets with Veterans. Ask.va.gov may fill in that gap, but it’s inaccessible and the Section 508 office (to their knowledge) has not been included in auditing it.
  * It may be difficult to track data on usage of the Section 508 email. Currently, there are no analytics, and it may be a manual intensive process.
  * Veterans who prefer analog methods feel excluded. “I don’t use tech. Everything you do pushes guys like me further and further out. My wife is good with tech but she’s not a Veteran. Never seems to get anywhere. I don’t do it.” “What Pat said, someone on the phone. Neither AIRA or BeMyEyes is accessible through a regular phone. For me, logging into VA.gov, not a Veteran, they can’t get to the things Brad needs to get to.”
* Tim Hornik (BVA)
  * Some disabled Veterans are providing feedback, but Tim hypothesizes many more may be sitting with inaccessible products. Tim shared an anecdote of a social care worker who sent an email to the Section 508 office about the cerner patient portal. Without that social care worker’s relationship with the disabled Veteran and their intervention, the issue may have never been highlighted.
  * VEO historically has not considered the disabled Veteran experience, but is critical to collecting feedback. As an advocate, Tim requested VEO to have mechanisms and pathways for feedback both virtually and physically at VA centers in the past. This doesn’t appear to have been implemented. 411 may be too overwhelmed to help. Tim noted that 411 call center employees may not have the time, training, and space to record accessibility feedback and forward it to the appropriate places to be fixed.
  * The Section 508 page needs an update and more research. The page has existed for 15 years and includes content on both internal department information and Veteran facing services. It’s linked to from the footer on all VA.gov pages as “Accessibility” which may be misleading. Tim is worried that it won’t be discoverable as a footer item. He knows that people use it (including VA staffers) because we direct them to go there from this external site.
  * We should explore paths of least resistance for improving Medallia feedback. Tim noted it may be easier to just include a link that acts as an offramp to another form for accessibility feedback within the Medallia feedback options.
  * In past work with rehab centers, people didn’t deliver feedback. Tim noted that people would complain about accessibility issues in meetings, but wouldn’t formally report on it.
* Djilan Yao (VEO)
  * Uncertain if any VEO projects have specifically addressed accessibility or disabled Veterans. It doesn’t seem to be something the measurement team has investigated yet, but could be an area of interest. Evan and Dan may be the next people to talk to (if possible).
  * There are 4 main methods of sending out surveys. Most (if not all) are powered by Medallia. This includes (1) surveys on VA.gov (feedback button and intercept survey), (2) QR codes in facilities that link to surveys, (3) IVR surveys over phone which are then input into Medallia, and (4) surveys sent out to sampled individuals by email which link to surveys.
  * We know some of those surveys (on VA.gov) have accessibility issues documented in Tiffany’s audit. But we’re uncertain if those issues exist on other Medallia surveys too. For example, if other surveys aren’t within a modal, they likely won’t share the same major issues related to magnification.
  * The base survey template is 508 compliant (WCAG 2.0), but may not cover issues beyond that scope. Surveys are developed for 508 compliance and tested internally through the 508 office. If a survey taker is using a software or technology outside of the 508 boundaries, we are not able to ensure it will work properly.

---

### MCT Chatbot as AVA Front Door

|Issue|[#193](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/193) and [#224](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/224)?|
|:--|:--|
|Date|2022-12|
|Team|VEO: VA Multi-channel Technology (MCT)|
|Background|This project will focus on researching and designing a conversational alternative to Ask VA (AVA) intake, which would allow users to submit tickets through a VA chatbot. Most participants didn’t have previous experience using AVA. Few participants have experience using a chatbot to submit a delayed-response secure message.|
#### Objectives
* Understand user expectations and comfortability with using a chatbot to perform AVA tasks, and how they would expect the new features to work.
* Determine pain points while submitting requests through AVA and discover how to mitigate them when submitting requests through the chatbot.
* Determine users’ comfort level in disclosing personal identifiable information (PII) within a chatbot conversation.
* Discover what kinds of tasks users would find most impactful or relevant to be able to accomplish through sending a secure message via chatbot.
* Understand user expectations around the intake and follow-up processes, as well as how they would expect to be informed and adopt the new feature.
#### Findings
* Users described chatbots being unhelpful due to a variety of reasons such as misinterpreting questions, unclear responses and inability to help with more complex tasks. Instead, some participants turn to secure messaging or reaching entities by phone in order to answer their questions.
* Participants mentioned using the chatbot for simple tasks and closed-ended questions, mostly recognizing a chatbot's language limitations.  Some mentioned analogous uses for a chatbot such as getting help from a phone provider or online shopping, but participants preferred access to a live agent in those instances, as well.
* The majority prioritize managing their health care through Secure Messaging while others mentioned seeking help for topics like education benefits, locating and filling out forms, and other VA services.
* Most participants view secure messages as an additional avenue to communicate with VA and value its ease of use, the ability to directly communicate complex issues with a human, and the ability to share relevant documentation instantly. Nevertheless, some participants found the response time to be inadequate and were frustrated when the responder was not knowledgeable enough to provide a solution.
* Participants generally felt that a chatbot could keep messages private, but most users felt reservations about chatbot security.
* Participants understood the advantages of logging in and would expect an authenticated query to yield more specific results. Although users understand that the chat would be limited to general inquiries if they decided to remain anonymous, 6 out of 9 participants favored an unauthenticated option. 
* Participants who had used AVA in the past mentioned they believed to be speaking directly with their provider when submitting a secure message, further underscoring their sense of security with the tool.
* Fewer participants felt comfortable inputting sensitive information into the chat setting than they do in a secure message.
* Most participants felt that basic information (contact information, subject, and issue description) is all that should be needed when submitting a ticket.  2 out of 9 participants felt VA should already have their basic information, expecting to only need to provide issue descriptions when submitting tickets.
* Participants agreed about the time it should take to receive a response in both channels; immediately in a chatbot and delayed via secure message. While most participants expect that submitting a ticket should take 5 minutes, they had split opinions on whether response times should vary based on issue topic.  Most figured that agent responses should be received back within 48 hours. Some thought all issues should be addressed with similar urgency while others felt that more complex issues could require more time.
> “If it’s a simple question, [I expect it to be] responded to on the spot. If it’s more complex, maybe it’s a couple hours later, maybe it’s the next day. So long as the information is conveyed to the person on the other side, then absolutely.”
* Most participants would expect immediate responses from a chatbot but would be willing to wait longer for a response from a live agent.
* Session participants expected to locate their historical and current tickets within a central space for easy access.  Participants wanted to be able to track the progress of their submitted tickets. Some participants also mentioned that they would expect to locate a ticket via a confirmation email or link. Some would expect to do so within chatbot.
* 4 out of 9 participants welcomed the ability to submit a ticket through a chatbot.
> “It will be kind of like having a normal conversation say like what can I help you with, submit my ticket then the chatbot starts to ask you your name, issue, whatever keywords that the chatbot can identify so then after everything and all the info that the chatbot needs, it says like this is a summary of what your ticket has, do you accept or do you decline. Then after it will say I'm sending a copy of this ticket to your email so you can have it.”
* Participants felt that if a chatbot were unable to answer their questions, the option to submit a ticket or connect with a human within the chatbot would be adequate alternatives.
* Some features participants appreciate in a chatbot are that it allows multitasking. In some cases, they also appreciate a chatbot’s ability to provide an adequate response without having to talk to a person.
* Most participants claimed they would trust the chatbot to route their requests to the right entities.
* Participants had varying opinions of how they would expect the process of submitting tickets to work and how to follow up with them. For example, following up on the ticket using chat or receiving an email.
> “If the agent knows that it might take three [or] four days, I would [expect] a message saying I’m working on it and maybe send an update like I haven’t forgotten about you and I’m working on it. That’s something you can show them on the ticket tab too on the title like the status, like a circle with a color green [or] orange.”
#### Recommendations
* VA associations help alleviate security concerns. Ensure the user knows who the message recipient will be. 
* Create an avenue for users to get meaningful answers while remaining anonymous. 
* Leverage the sense of security created by secure messaging applications and convey it within the chatbot conversation.
* Enhance a user’s sense of security by leveraging information available when authenticated and confirm chatbot security measures already in place.
* Leverage stored/available data when a user is authenticated and only request confirmation of data, data from unauthenticated users, or additional data relevant to a specific query.
* Users may find it reassuring to see the process status of a message. Avoid confusion and frustration by providing transparency into the process. It will be important to set expectations at the start that submitting a ticket through the chatbot will result in a delayed response from an agent.
* Users will likely also want to be able to track, be alerted of, and manage their submitted delayed-response tickets. Further probing is needed to assess user preferences for how they want to reply once an initial response is received from an AVA source.
* Further probing is needed to assess specific thoughts on the ticket submission journey in a conversational chat environment.
* Participants’ preference for interaction with agents indicates favorable views for adopting chatbot as AVA’s intake. Surface opinions suggest that a delayed-response option alleviates users’ hesitations about interacting with a chatbot. However, further probing is needed to assess finer points of a merged tool.
* Provide transparency into where the ticket will be routed, to proactively address concerns of the request not making it to the right person.

---

### MCT Virtual Agent Chatbot Login.Gov and ID.me Moderated Interviews

|Issue|[#205](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/205)|
|:--|:--|
|Date|2022-12|
|Team|VEO: VA Multi-channel Technology (MCT)|
|Background|This project will focus on the desired experience for Veterans seeking login assistance for their new or existing Login.gov and ID.me accounts from the VA chatbot.|
#### Objectives
* Understand user expectations and desires around the information and interactions the VA chatbot can provide regarding login assistance for their new or existing Login.gov and ID.me accounts.
* Which keywords would a user expect to type in for help with a Login.gov or ID.me account?
* Are the help tasks what the user expects for an existing Login.gov or ID.me account?
* What additional tasks associated with Login.gov or ID.me account assistance should the chatbot be able to perform?
* How do users feel about the button layout and navigation between button stacks?
#### Findings
* Some participants initially struggled with getting the result they wanted based on the keywords they chose to type.
> "I asked a very straightforward question and it doesn't know what I'm talking about."
* Most participants had a reasonable idea of wha tinformation the 'I don't know' button would return and that it would likely provide more information on account types.
* Particiapnts thought that the language of the quote was too much, confusing and felt like you're 'talking to an algorithm.'
* Login.gov options (forgot my password, sending my ID, etc.) made sense and were expected. Some participants didn't know what 'sending my ID' meant.
* Participants stated that much of what the chatbot provided was something they might expect, and it was clear what they would do next.
* Participants shared that they liked the navigation of the "See more options" and "Back" buttons. They thought this was easy, helpful, and familiar to them.
> "Oh, that's amazing because I can always go back but if I need more options, I can view those and still go back. Other ones like Amazon force you to click the next one and then if you don't click the desired one it brings you back to a brand-new page...it's a waste of time. So, allowing me to go back is really nice."
* Most participants stated they didn’t mind leaving VA.gov to receive the answer they were looking for and get further information.
* Most also liked that a separate tab was opened so they could return to the VA site after. 
* Most participants were unclear about the "What you'll need" button and what information it might provide. They were more confused after clicking and receiving seemingly mismatched information.
* As previously reflected, users began getting frustrated after trying different variations of questions to ask only to receive unrelated information. 
> "I wish it would cluster words together... like when you type email, there should be more associations then that one that first popped up. I feel like the clustering association could be setup differently."
> "Typing in the something and nothing comes up you get a little discouraged. But then I said maybe I'm not asking the right questions... by the last scenario I put ID.me account and got everything I needed which made me feel good."
* Most participants welcomed the idea of leaving the chatbot to be provided with a help article that gave them more information than they expected.
> "I like how it would take you to a knowledge-based article that would give you a full explanation."
* Several participants mentioned a live-agent feature when asked if anything was lacking. Some participants said they preferred to interact with an actual human representative if they couldn't find the answer they were looking for.
> “I guess I'm used to more human interaction...talking with an actual person. If they didn't understand me they can ask me more questions and narrow down exactly what I'm looking for instead of just providing me a link that might not always answer my question."
#### Recommendations
* Pursue more word associations based on what the user might type.
* Ensure language is simple and concise.
* Consider updating 'Sending my ID' with a more straightforward name.
* Consider updating the "What you'll need" button with a clear alternate title and ensure the associated information matches. 

---

### Chatbot Feature Prioritization

|Issue|[#175](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/175)|
|:--|:--|
|Date|2022-08|
|Team|Virtual Agent|
|Background|The Chatbot is a self-service platform that can be accessed at any time by Veterans. The chatbot aims to provide value to Veterans by increasing awareness of existing VA self-service tools, decreasing the time Veterans spend waiting for an outcome, and allowing them 24/7 access to either anonymous or secure support. The chatbot was initially released in February 2022 so it is fairly new and unfamiliar to Veterans. Finally, the chatbot is currently situated as a subset of the VA Contact Us and can be accessed directly here.|
#### Objectives
* What features would users like to see prioritized based upon the following issues: the ability to provide users with sign in related information, problem escalation, password reset, and account creation?
* What are the primary pain points that exist around sign in related issues with users?
* How are users currently addressing and navigating these tasks?
#### Findings
Unable to access.

---

### MCT Omnichannel Experience: Co-Design Phase II

|Issue|[#127](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/127)|
|:--|:--|
|Date|2022-06|
|Team|VEO: VA Multi-Channel Technology (MCT)|
|Background|This project will focus on the desired experience for Veterans seeking information from a VA.gov chatbot. User research will focus on the desirability of future state of Virtual Agent features to inform the longer-term roadmap.|
#### Objectives
* Understand user expectations for the level of information a virtual agent can provide regarding the disability rating and compensation, as well as the appeals process.
* Learn the desired interactions and depth of information the Virtual Agent needs to be able to provide.
#### Findings
* Users are likely to end the interaction with the chatbot after they have received the answers they were looking for and want a way to conclude the conversation.
* Some users disliked the guided experience with the buttons because they found it limiting and felt they were not in control of the conversation. Additionally, feelings of frustration arose when responses felt redundant and there was no way out.
* A few users preferred the simple, straight--forward experience of being provided a link to read information for themselves. Some of these users would only use a chatbot for high--level, basic level, basic questions, rather than information on their personal case.
* Most users appreciated being provided a link with additional information and resources and would click to read more.
* In some instances, users felt the link was a distraction and could lead to the user accidentally leaving the chat.
* Some users liked that the chatbot provided resources such as links to PDFs and forms and were likely to download them for future use.
* Some users felt overwhelmed or confused when being provided too many options or too much detail, leading them towards ending the conversation. Some also felt the segmented and concise response helps them fully digest the information and not miss any key details.
* Users generally liked the step-by-step guidance, which increased engagement because they believed it helped break down complex tasks into digestible pieces. This can be particularly helpful for newer users.
* Some users want the chatbot to provide information on their case––specific next steps, such as filing a claim or appealing online.
* Many users wanted or expected the chatbot to have the ability to provide personalized responses based on their unique situation. To ensure they receive this experience, most users will articulate their questions in complete sentences and provide case specific information. Some would not have a problem providing their personally identifiable information within the chatbot, while others would expect the bot to pull it from their account.
* Users appreciated the guided experience provided in the chatbot and prefer that over searching on VA.gov as it sifts through information for them. Conversely, searching on VA.gov is viewed as a futile and frustrating task.
* Some users would opt for outside sources rather than VA to find answers. Additionally, some would start with other channels instead of coming to the chatbot to find information.
* Users were satisfied with the experience when the chatbot provided comprehensive, digestible and intuitive responses. In many cases, a general idea or a non-overwhelming response was a satisfactory answer.
* Many users expressed a desire to speak with a live person instead of a chatbot. In some cases, they would like for a chatbot to have the ability to transfer directly to a live agent, others would skip the bot and start with a live person because they appreciate the active conversational aspect.
#### Recommendations
* Include options to "continue" or to "finish" conversation after each pathway to provide a clear way to navigate.
* Make it clear to users they can override the suggested button pathways by typing in their questions.
* When possible, provide links toward the end of a topic area and open the link in a separate tab.
* Ensure that only relevant information and options are provided to the user to not overwhelm or confuse them.
* Ensure responses are segmented and concise to help users fully digest the information and not miss any key details.
* As many perceive the task of calculating disability ratings as an already lengthy process, ensure all responses and steps provided are clear and concise. If possible, allow users the ability to input their own disability ratings to help contextualize how their determination was reached.
* Leverage user profiles and information [PII/PHI] provided through chat to ensure solutions are relevant and personalized to the user's unique needs.
* Include interactions such as tooltips, an option to save the chat for reference later, and animations to help users contextualize information.
* When available, give users the option to connect to a live agent in the beginning of the conversation and upon chatbot failure to provide adequate resolution.

---

### VA Orchid, Virtual Agent Chatbot

|Issue|[#151](https://github.com/orgs/department-of-veterans-affairs/projects/880/views/1?filterQuery=chatbot&pane=issue&itemId=21794331)|
|:--|:--|
|Date|2022-07|
|Team|Virtual Agent|
|Background|Our research will attempt to gain insight on the reason for the lack of completion of the feedback survey. The research will also help us understand how users expect to be taken through a password reset flow. Finally, we have identified four areas to expand the chatbot into and this research will help us prioritize the features we focus on for users.|
#### Objectives
* Gain insight on lack of feedback survey completion
* Take users through a flow to reset their password and gain insight on the expected flow
* Gain in	sight on future chatbot feature prioritization with users
#### Findings
Unable to access.

---

### MCT VHA Virtual Agent Research

|Issue|[#148](https://github.com/orgs/department-of-veterans-affairs/projects/880/views/1?filterQuery=chatbot&pane=issue&itemId=21794312)|
|:--|:--|
|Date|2022-06|
|Team|VEO: VA Multi-Channel Technology (MCT)|
|Background|This project will focus on the desired experience for Veterans, caregivers, and family members seeking information from a VHA chatbot. User research will focus on the desirability and perceived usefulness of health and health care related content and information, which will inform future product roadmaps and even content creation.|
#### Objectives
* Understand user expectations for the type of information a chatbot can provide about VHA services, features, and other information Veterans might expect from a chatbot.
* Learn what the desired VHA interactions and features are that the chatbot needs to be able to perform.
#### Findings
* Users wanted the ability to order and refill prescriptions through a VA chatbot.
* Users had varied interest in having a chatbot provide medical and dental coverage and provide medical and dental coverage information.
* Most participants expressed a strong desire to manage their medical appointments using a VA manage their medical appointments using a VA chatbot. Many users reported difficulties managing their appointments through current managing their appointments through current VA platforms and methods.
* Several participants expressed desires for the VA chatbot to check into appointments and VA chatbot to check into appointments and communicate onsite delays.
* Most participants stated that seeking medical records, test results, and receiving notifications records, test results, and receiving notifications of results were top needs.
* Most users found the ability to request or change to a new provider highly desirable.
* Users expressed frustrations with the current process of requesting referrals and options for the process of requesting referrals and options for specialists or Community Care needs.
* Users expressed a desire for an additional avenue for communicating with providers.
* Due to the amount of information and segmentation of experience for different VA touchpoints, many users struggle to find information that suits their needs.
* Users dislike the experience of contacting VA as it is difficult reaching someone, specifically someone who can provide an adequate or timely solution.
* Some users want a chatbot to help locate VA facilities providing services that suit their unique care needs.
* Users liked chatbots that are intuitive and offer guiding features, saying that is what gains their trust. Nevertheless, some users said those attributes still may not be enough to overcome their preferences for live agent chats.
* A few users expressed interest in a chatbot having functions that can aid in claims, appeals, and other Veterans Benefits Administration related financial inquiries.

---

### MCT Omnichannel Experience: Co-Design

|Issue|[#96](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/96)|
|:--|:--|
|Date|2022-03|
|Team|VEO: VA Multi-Channel Technology (MCT)|
|Background|This project will focus on the desired experience for Veterans seeking information from a VA.gov chatbot. User research will focus on the desirability of future state of Virtual Agent features to inform the roadmap for upcoming configuration.|
#### Objectives
* Understand how users will interact with a VA chatbot to retrieve VA facilities information.
* Understand the type of language Veterans used to communicate their needs. Are they able to understand the current VA language and terminology? 
* Validate the type of information users are searching for regarding specific VA facilities. 
* Learn what, if any information related to VA facilities that Veterans would like but are not currently available on VA.gov
#### Findings
* Many users expressed that they would search for information using VA.gov only when specific needs arise and not for browsing.
* Most users solely rely on private search engines for VA -related information as they offer the most direct and relevant results. This reliance on private search engines is often attributed to negative past experiences using the VA.gov search feature.
* Some users were confused by the term “Virtual Agent” and believed they would interact with a customer service representative or live agent.
* Users expressed frustration when chatbots provide generic or canned responses, leading some to avoid chatbots altogether, and opt to call a live agent or search for a resolution themselves.
* Users become frustrated when a chatbot is unable to recognize their inquiry and forces them to be stuck in a loop. Users expect the Virtual Agent to accurately route them towards a solution. If it fails to understand intent, it should present users with probing questions.
* Many users prefer the personalized touch of a human interaction, along with the efficacy a live agent provides. Users expect the ability to escalate within a reasonable timeframe during the same interaction.
* Users want personalized results tailored to their profile and unique situation when engaging with a Virtual Agent, including comprehensive guidance to navigate complex and opaque processes, like claims and payments.

---

### Virtual Agent Authentication Usability Test

|Issue|[#97](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/97)|
|:--|:--|
|Date|2022-03|
|Team|VEO: VA Multi-Channel Technology (MCT)|
|Background|We are releasing an unauthenticated chatbot in Feb 2022 that will act as a new way to access information to the Veterans, and an authenticated version in April 2022, that will provide personalization and features to access private information, such as claims and appeals status. This tests the flow from non authenticated to authentication.|
#### Objectives
* Is the in-chat bot authentication process clear?
* Do users want/need to sign out from the chatbot?
* Do users need a visual indication for having signed in?
* Are users able to easily find the Virtual Agent?
* What do users currently understand what the chatbot can do?
#### Findings
* Users eventually located the Virtual Agent option on the ”Contact Us” VA.gov webpage, but the Agent’s location in the call-out web element was not immediately apparent.
* Users described an ideal location for a Virtual Agent access point on their screens at the “bottom-right.”
* Users also expressed desires for a chat experience that can collapse and minimize or follow the user during their browsing session.
* None of the users noticed the lock icon at first glance. Most users identified being logged in by seeing the “Hector” name in the top right corner of the page.
* Most users expected a blue sign out button to be available within the Virtual Agent. After the initial confusion, users signed out from the navigation bar.
* Users also expressed that after their Virtual Agent interaction, they would explicitly sign out of their profile.
#### Recommendations
* Group the beta testing Virtual Agent access point in a similar manner as other contact channels.
* Position a minimizable, roaming chat experience at bottom-right of browser screen.
* Remove the lock icon in the chat window.
* Add a sign out button as an additional option in actions that the Virtual Agent presents to the user.

---

### VSP, Ask VA - Dashboard (Business, Personal)

|Issue|Not available. [Link to folder](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/iris/research/ava/2022-02/research-plan.md).|
|:--|:--|
|Date|2022-03|
|Team|VSP Contact Center|
|Background|This study is being conducted by the VSP Contact Center team. The study follows the Ask VA (AVA) tool, which enables veterans and VA.gov users to submit inquiries digitally. The AVA product team released a new tab function with labels (Business, Personal) in December 2021. The study will provide feedback for this new feature to the AVA product team. This research was done with SCOs (School Certifying Officials) that serve Veterans at higher education institutions. They are primary users of AVA. Participants were sourced through the VA Call Center team.|
#### Objectives
* Document and prioritize any outstanding usability concerns with AVA, including both inquiry submission and the authenticated dashboard.
* Verify the implementation of new dashboard upgrades, and help SCOs and VA employees with handling caseloads in AVA.
#### Findings
* 3 of the 5 participants had initial login issues with ID.me or got errors in Chrome and had to switch to Internet Explorer.
* All were able to locate the Business and Personal tabs after submitting inquiries specific to GI Bill.
* The number of inquiries made by the SCOs could range from 25-50 a month.
* New users had difficulty understanding the function of the Business and Personal tabs.
* SCO users that had 1 month of usage or more did like the auto-sorting of inquiries for their workflow.
* 2 of the participants referenced difficulties their co-workers may face using AVA.
* All recommended a function to find inquiries in their AVA Dashboard faster.
* 3 of the 5 participants had concerns about adjusting their PI data on the Review page before submittal and confusion about how the fields were auto-populating.
* One person mentioned a workflow where they need to print a PDF of their dashboard and/or a specific inquiry for internal filing. This function often doesn’t work in Chrome.
#### Recommendations
* Research onboarding functions or reminders for the dashboard view.
* Tabs can be renamed per SCO preference.
* Audit needed for the beginning of the AVA form regarding inquiry type. One of the participants highlighted specific keywords related to GI Bill that were not in the drop down.

---

### Needs of Spanish Speaking Veterans for the Virtual Agent

|Issue|[#66](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/66)|
|:--|:--|
|Date|2022-01|
|Team|Virtual Agent|
|Background|With the upcoming release of the Virtual Agent chatbot, the needs for internationalization and making available content for veterans that would prefer to use Spanish or other language as a preferred language are unclear. This research is an effort to understand how the needs of this group differ from the English speaking veterans.|
#### Objectives
* How do needs from Spanish speaking Veterans differ from the English speaking Veterans regarding self service through the chatbot?
* How do Spanish speaking Veterans interact with a chatbot?
#### Findings
* Veterans with services available in their preferred language expressed better satisfaction with the VA.
* Veterans with Spanish as preferred language have relied on a third party or acted as support for other Spanish speaking Veterans.
* Information sharing in Spanish is mostly done verbally, with information lost in translation.
* Veterans showed the need for information consistent with previous research, but preferred having it in their preferred language.
* Most important: emergency services, health, general benefits, solving benefits problems.
* Challenges navigating the VA website were: inconsistent language across pages, most resources in Spanish as PDFs, not knowing what to search for.
* Challenges related with interacting in English being: specialized language, time and effort , and comfort of expression.
* Veterans see the Virtual Agent as a guide to navigate the VA.
* Veterans found that with providing them a link it was very time and effort saving.
* Veterans mentioned if the Virtual Agent was in Spanish they would expect the content of -the links to also be in Spanish.
* Veterans would prefer to use it in their preferred language, but would use it in English if it was the only available option.

---

### MCT Virtual Agent Facilities Conversational Design

|Issue|[#80](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/80)|
|:--|:--|
|Date|2022-01|
|Team|VEO: VA Multi-Channel Technology (MCT)|
|Background|This project will focus on the desired experience for Veterans seeking information about VA facilities with a VA.gov chatbot. User research will focus both on the desirability of specific facilities-related features and on the conversational design of these features. Facilities information and content will be based on the content already available on VA.gov and through the Lighthouse API.|
#### Findings
* When searching for nearby VA facilities, users liked seeing multiple options for comparison.
* Users wanted detailed facility information such as address, hours of operation, facility status, and phone numbers during their VA facility search.
* While most participants understood VA.gov’s facility terminology, a few users were confused by the term "VA Health," and did not expect Specialties or Services to be under the "VA Health" option.
* While most participants had their own reliable transportation, they were aware that others might need transportation assistance.

#### Recommendations
* Display at least two nearby locations with the option to view additional locations if desired.
* Provide full facility information
* Add additional, clarifying examples between parentheses for certain categories, ex. “VA Health (Medical Centers & Clinics).”
* Include information on transportation assistance where available.

---

### Virtual Agent Automated Content and Claims Feature Usability Testing

|Issue|[#45](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/45)|
|:--|:--|
|Date|2021-11|
|Team|Virtual Agent|
|Background|This research was for Veteran preference for drupal content responses, claims feature feedback and to learn other topics Veterans would be interested to engage with the chatbot.|

---

### VSP, Ask VA

|Issue|Not available. [Link to folder](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/iris/research/ava/2021-07/research-plan.md).|
|:--|:--|
|Date|2021-07|
|Team|VSP Contact Center|
|Background|This study is being conducted by the VSP Contact Center team. The study follows the Ask VA (AVA) tool, which enables veterans and VA.gov users to submit inquiries digitally.|

---

### Virtual Agent Inclusive Design interviews

|Issue|[#1](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/1)|
|:--|:--|
|Date|2021-06|
|Team|Virtual Agent|
|Background|The virtual agent/chatbot will eventually be hosted on Va.gov. Exact location(s) to be determined. Ultimately, the virtual agent’s goal is to provide responses based on existing Va.gov content to enable and encourage self service behaviors. This project is part of the larger Omnichannel strategy (led by VEO) to provide veterans with seamless access to information.|

---

### Ask VA

|Issue|Not available. [Link to folder](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/iris/research/ava/2021-04/research-plan.md).|
|:--|:--|
|Date|2021-04|
|Team|VSP Contact Center|
|Background|What, if any, changes need to be implemented before the full release of the Ask VA (AVA). Explore topics such as Customer Satisfaction & Trust, Findability and (Task) Service Completion. Testing full AVA experience. Testing the content of the form.|

---

### VA.gov Relaunch

|Issue|Not available; and this work contains multiple studies. [Link to folder](https://github.com/department-of-veterans-affairs/va.gov-team/tree/master/products/va-gov-relaunch-2018).|
|:--|:--|
|Date|2018|
|Team|Web Brand Consolidation(?)|
|Background|The problem this initiative aimed to solve was that Veterans do not have a single place to find, apply for, and manage their health care and benefits. On Veterans Day of 2018, VA.gov was relaunched with a consolidation of the various VA.gov digital properties (MHV, eBenefits, Vets.gov). User research for these efforts was captured in this [plan](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/va-gov-relaunch-2018/user-research/user-research-plan.md).|

## Studies related to forms or one thing per page pattern

### Profile Notification Settings, Add Email Channel

|Issue|[#214](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/214)).|
|:--|:--|
|Date|01-2023|
|Team|Profile, Authenticated Experience|
|Background|Currently, the existing notification preferences we support all happen to only use text message as their means for getting in touch with users. However, we know that we'll soon need to support notifications that use email as a channel, and maybe some that support both text message and email as options. We want to do some research around how we can incorporate this additional option into the notification preferences interface so that we're ready to move quickly once this becomes a need for both users and stakeholders.|
#### Objectives
* Determine usable and scalable approach for adding email as a channel.
* Determine usable and scalable approach for adding more notification preferences to the page.
* Determine what level of information people need in order for them to decide whether they want to edit/update their preferences.
#### Findings
* The auto-save edit pattern in current designs was unanimously preferred to the read/edit (edit on a separate page) alternative. Participants were easily able understand and interact with our current auto-save pattern, even with more notifications and channels than we have on the page today.
* People were able to work through these problems without significant guidance from the moderator, but still found the auto-save pattern to be easier and faster to navigate. This further supports the findings from our [profile editing evaluation study](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/identity-personalization/profile/Research/2022-09-profile-editing-evaluation/findings-summary.md) that a “one thing per page” approach is not ideal for the short forms in the VA.gov profile.
* No one was confused by the lack of a save button.
* People were not totally clear on what to expect from notifications we’ll be bringing over from My HealtheVet.
* 7 of 8 participants easily navigated the path to add their email address.
* The repetition of the prompt to add an email address wasn’t overwhelming for most people.
* Both variations of the design were equally usable on desktop and mobile.
* Some participants were not clear about where their notifications would be delivered.
#### Recommendations
* Use the pattern in the auto-save prototype for notification settings as we add channels and notification options.
* The prototype replaced the radio buttons we have today with checkboxes. This was easily understood by participants and allows us to cut the number of inputs in half, resulting in a cleaner user interface.
* Learn more about content of My HealtheVet notifications, and update content accordingly to set clear expectations about what they are.
* Reconsider how we are encouraging people to add their email address to their profile.
* Explore how we might make the input message pattern more accessible.
* Explore how we might surface meaningful and relevant links to people in the notification settings section.
