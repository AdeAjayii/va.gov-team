# Initial desk research of previous VA studies
Last updated by @tygindraux on June 1, 2023

## List of studies
* [MCT HCD Chatbot as AVA Frontdoor - February 2023](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#mct-hcd-chatbot-as-ava-frontdoor)
* [Multi-channel Technologies (MCT) Chatbot as AVA Front Door - Dec 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#multi-channel-technologies-mct-chatbot-as-ava-front-door)
* [MCT Virtual Agent Chatbot Login.Gov and ID.me Moderated Interviews - Dec 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#mct-virtual-agent-chatbot-logingov-and-idme-moderated-interviews)
* [Chatbot Feature Prioritization - August 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#chatbot-feature-prioritization)
* [MCT Omnichannel Experience: Co-Design Phase II - June 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#mct-omnichannel-experience-co-design-phase-ii) 
* [MCT VHA Virtual Agent Research - June 24, 2022](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/ask-va/research/Notes/Initial%20desk%20research%20of%20previous%20VA%20studies.md#mct-omnichannel-experience-co-design-phase-ii)
* [VA Orchid, Virtual Agent Chatbot - June 14, 2022]()
* [MCT Omnichannel Experience: Co-Design - March 2022]()
* [Virtual Agent Authentication Usability Test - March 2022]()
* [VSP, Ask VA - Dashboard (Business, Personal) - January 2022]()
* [Needs of Spanish Speaking Veterans for the Virtual Agent - January 2022]()
* [MCT Virtual Agent Facilities Conversational Design - January 2022]()
* [Virtual Agent Automated Content and Claims Feature Usability Testing - Nov 2021]()
* [VSP, Ask VA - July 2021]()
* [Virtual Agent Inclusive Design interviews - June 2021]()
* [Ask VA - April 2021]()

## Details
### MCT HCD Chatbot as AVA Frontdoor

|Issue|[#224](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/224)|
|:--|:--|
|Date|2023-02|
|Team|VEO: VA Multi-channel Technology (MCT)|
|Background|This project will focus on testing a clickable chatbot prototype as a conversational alternative to Ask VA (AVA) intake, to assess the desired experience for Veterans to submit tickets through a VA chatbot.|

#### Objectives
* Understand user preference around intent recognition, specifically through a guided vs. conversational experience in which varying levels of details are collected from the user
* Determine user expectations around the escalation process of an existing ticket
* Determine the level of detail and cadence of confirmation messages presented to the user through the intake process regarding ticket submission
* Understand the ideal timeframe and desired follow up method by contact center agent regarding submitted ticket
#### Findings
Unable to access. I’ve asked Shane (Research Ops).

---

### Multi-channel Technologies (MCT) Chatbot as AVA Front Door

|Issue|[#193](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/193)|
|:--|:--|
|Date|2022-12|
|Team|VEO: VA Multi-channel Technology (MCT)|
|Background|This project will focus on researching and designing a conversational alternative to Ask VA (AVA) intake, which would allow users to submit tickets through a VA chatbot. Most participants didn’t have previous experience using AVA. Few participants have experience using a chatbot to submit a delayed-response secure message.|
#### Objectives
* Understand user expectations and comfortability with using a chatbot to perform AVA tasks, and how they would expect the new features to work.
* Determine pain points while submitting requests through AVA and discover how to mitigate them when submitting requests through the chatbot.
* Determine users’ comfort level in disclosing personal identifiable information (PII) within a chatbot conversation.
* Discover what kinds of tasks users would find most impactful or relevant to be able to accomplish through sending a secure message via chatbot.
* Understand user expectations around the intake and follow-up processes, as well as how they would expect to be informed and adopt the new feature.
#### Findings
* Users described chatbots being unhelpful due to a variety of reasons such as misinterpreting questions, unclear responses and inability to help with more complex tasks. Instead, some participants turn to secure messaging or reaching entities by phone in order to answer their questions.
* Participants mentioned using the chatbot for simple tasks and closed-ended questions, mostly recognizing a chatbot's language limitations.  Some mentioned analogous uses for a chatbot such as getting help from a phone provider or online shopping, but participants preferred access to a live agent in those instances, as well.
* The majority prioritize managing their health care through Secure Messaging while others mentioned seeking help for topics like education benefits, locating and filling out forms, and other VA services.
* Most participants view secure messages as an additional avenue to communicate with VA and value its ease of use, the ability to directly communicate complex issues with a human, and the ability to share relevant documentation instantly. Nevertheless, some participants found the response time to be inadequate and were frustrated when the responder was not knowledgeable enough to provide a solution.
* Participants generally felt that a chatbot could keep messages private, but most users felt reservations about chatbot security.
* Participants understood the advantages of logging in and would expect an authenticated query to yield more specific results. Although users understand that the chat would be limited to general inquiries if they decided to remain anonymous, 6 out of 9 participants favored an unauthenticated option. 
* Participants who had used AVA in the past mentioned they believed to be speaking directly with their provider when submitting a secure message, further underscoring their sense of security with the tool.
* Fewer participants felt comfortable inputting sensitive information into the chat setting than they do in a secure message.
* Most participants felt that basic information (contact information, subject, and issue description) is all that should be needed when submitting a ticket.  2 out of 9 participants felt VA should already have their basic information, expecting to only need to provide issue descriptions when submitting tickets.
* Participants agreed about the time it should take to receive a response in both channels; immediately in a chatbot and delayed via secure message. While most participants expect that submitting a ticket should take 5 minutes, they had split opinions on whether response times should vary based on issue topic.  Most figured that agent responses should be received back within 48 hours. Some thought all issues should be addressed with similar urgency while others felt that more complex issues could require more time.
> “If it’s a simple question, [I expect it to be] responded to on the spot. If it’s more complex, maybe it’s a couple hours later, maybe it’s the next day. So long as the information is conveyed to the person on the other side, then absolutely.”
* Most participants would expect immediate responses from a chatbot but would be willing to wait longer for a response from a live agent.
* Session participants expected to locate their historical and current tickets within a central space for easy access.  Participants wanted to be able to track the progress of their submitted tickets. Some participants also mentioned that they would expect to locate a ticket via a confirmation email or link. Some would expect to do so within chatbot.
* 4 out of 9 participants welcomed the ability to submit a ticket through a chatbot.
> “It will be kind of like having a normal conversation say like what can I help you with, submit my ticket then the chatbot starts to ask you your name, issue, whatever keywords that the chatbot can identify so then after everything and all the info that the chatbot needs, it says like this is a summary of what your ticket has, do you accept or do you decline. Then after it will say I'm sending a copy of this ticket to your email so you can have it.”
* Participants felt that if a chatbot were unable to answer their questions, the option to submit a ticket or connect with a human within the chatbot would be adequate alternatives.
* Some features participants appreciate in a chatbot are that it allows multitasking. In some cases, they also appreciate a chatbot’s ability to provide an adequate response without having to talk to a person.
* Most participants claimed they would trust the chatbot to route their requests to the right entities.
* Participants had varying opinions of how they would expect the process of submitting tickets to work and how to follow up with them. For example, following up on the ticket using chat or receiving an email.
> “If the agent knows that it might take three [or] four days, I would [expect] a message saying I’m working on it and maybe send an update like I haven’t forgotten about you and I’m working on it. That’s something you can show them on the ticket tab too on the title like the status, like a circle with a color green [or] orange.”
#### Recommendations
* VA associations help alleviate security concerns. Ensure the user knows who the message recipient will be. 
* Create an avenue for users to get meaningful answers while remaining anonymous. 
* Leverage the sense of security created by secure messaging applications and convey it within the chatbot conversation.
* Enhance a user’s sense of security by leveraging information available when authenticated and confirm chatbot security measures already in place.
* Leverage stored/available data when a user is authenticated and only request confirmation of data, data from unauthenticated users, or additional data relevant to a specific query.
* Users may find it reassuring to see the process status of a message. Avoid confusion and frustration by providing transparency into the process. It will be important to set expectations at the start that submitting a ticket through the chatbot will result in a delayed response from an agent.
* Users will likely also want to be able to track, be alerted of, and manage their submitted delayed-response tickets. Further probing is needed to assess user preferences for how they want to reply once an initial response is received from an AVA source.
* Further probing is needed to assess specific thoughts on the ticket submission journey in a conversational chat environment.
* Participants’ preference for interaction with agents indicates favorable views for adopting chatbot as AVA’s intake. Surface opinions suggest that a delayed-response option alleviates users’ hesitations about interacting with a chatbot. However, further probing is needed to assess finer points of a merged tool.
* Provide transparency into where the ticket will be routed, to proactively address concerns of the request not making it to the right person.

---

### MCT Virtual Agent Chatbot Login.Gov and ID.me Moderated Interviews

|Issue|[#205](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/205)|
|:--|:--|
|Date|2022-12|
|Team|VEO: VA Multi-channel Technology (MCT)|
|Background|This project will focus on the desired experience for Veterans seeking login assistance for their new or existing Login.gov and ID.me accounts from the VA chatbot.|
#### Objectives
* Understand user expectations and desires around the information and interactions the VA chatbot can provide regarding login assistance for their new or existing Login.gov and ID.me accounts.
* Which keywords would a user expect to type in for help with a Login.gov or ID.me account?
* Are the help tasks what the user expects for an existing Login.gov or ID.me account?
* What additional tasks associated with Login.gov or ID.me account assistance should the chatbot be able to perform?
* How do users feel about the button layout and navigation between button stacks?
#### Findings
Unable to access. I’ve asked Shane (Research Ops).

---

### Chatbot Feature Prioritization

|Issue|[#175](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/175)|
|:--|:--|
|Date|2022-08|
|Team|Virtual Agent|
|Background|The Chatbot is a self-service platform that can be accessed at any time by Veterans. The chatbot aims to provide value to Veterans by increasing awareness of existing VA self-service tools, decreasing the time Veterans spend waiting for an outcome, and allowing them 24/7 access to either anonymous or secure support. The chatbot was initially released in February 2022 so it is fairly new and unfamiliar to Veterans. Finally, the chatbot is currently situated as a subset of the VA Contact Us and can be accessed directly here.|
#### Objectives
* What features would users like to see prioritized based upon the following issues: the ability to provide users with sign in related information, problem escalation, password reset, and account creation?
* What are the primary pain points that exist around sign in related issues with users?
* How are users currently addressing and navigating these tasks?
#### Findings
Unable to access. I need to chase.

---

### MCT Omnichannel Experience: Co-Design Phase II

|Issue|[#127](https://github.com/department-of-veterans-affairs/va.gov-research-repository/issues/127)|
|:--|:--|
|Date|2022-06|
|Team|VEO: VA Multi-Channel Technology (MCT)|
|Background|This project will focus on the desired experience for Veterans seeking information from a VA.gov chatbot. User research will focus on the desirability of future state of Virtual Agent features to inform the longer-term roadmap.|
#### Objectives
* Understand user expectations for the level of information a virtual agent can provide regarding the disability rating and compensation, as well as the appeals process.
* Learn the desired interactions and depth of information the Virtual Agent needs to be able to provide.
#### Findings
* Users are likely to end the interaction with the chatbot after they have received the answers they were looking for and want a way to conclude the conversation.
* Some users disliked the guided experience with the buttons because they found it limiting and felt they were not in control of the conversation. Additionally, feelings of frustration arose when responses felt redundant and there was no way out.
* A few users preferred the simple, straight--forward experience of being provided a link to read information for themselves. Some of these users would only use a chatbot for high--level, basic level, basic questions, rather than information on their personal case.
* Most users appreciated being provided a link with additional information and resources and would click to read more.
* In some instances, users felt the link was a distraction and could lead to the user accidentally leaving the chat.
* Some users liked that the chatbot provided resources such as links to PDFs and forms and were likely to download them for future use.
* Some users felt overwhelmed or confused when being provided too many options or too much detail, leading them towards ending the conversation. Some also felt the segmented and concise response helps them fully digest the information and not miss any key details.
* Users generally liked the step-by-step guidance, which increased engagement because they believed it helped break down complex tasks into digestible pieces. This can be particularly helpful for newer users.
* Some users want the chatbot to provide information on their case––specific next steps, such as filing a claim or appealing online.
* Many users wanted or expected the chatbot to have the ability to provide personalized responses based on their unique situation. To ensure they receive this experience, most users will articulate their questions in complete sentences and provide case specific information. Some would not have a problem providing their personally identifiable information within the chatbot, while others would expect the bot to pull it from their account.
* Users appreciated the guided experience provided in the chatbot and prefer that over searching on VA.gov as it sifts through information for them. Conversely, searching on VA.gov is viewed as a futile and frustrating task.
* Some users would opt for outside sources rather than VA to find answers. Additionally, some would start with other channels instead of coming to the chatbot to find information.
* Users were satisfied with the experience when the chatbot provided comprehensive, digestible and intuitive responses. In many cases, a general idea or a non-overwhelming response was a satisfactory answer.
* Many users expressed a desire to speak with a live person instead of a chatbot. In some cases, they would like for a chatbot to have the ability to transfer directly to a live agent, others would skip the bot and start with a live person because they appreciate the active conversational aspect.
#### Recommendations
* Include options to "continue" or to "finish" conversation after each pathway to provide a clear way to navigate.
* Make it clear to users they can override the suggested button pathways by typing in their questions.
* When possible, provide links toward the end of a topic area and open the link in a separate tab.
* Ensure that only relevant information and options are provided to the user to not overwhelm or confuse them.
* Ensure responses are segmented and concise to help users fully digest the information and not miss any key details.
* As many perceive the task of calculating disability ratings as an already lengthy process, ensure all responses and steps provided are clear and concise. If possible, allow users the ability to input their own disability ratings to help contextualize how their determination was reached.
* Leverage user profiles and information [PII/PHI] provided through chat to ensure solutions are relevant and personalized to the user's unique needs.
* Include interactions such as tooltips, an option to save the chat for reference later, and animations to help users contextualize information.
* When available, give users the option to connect to a live agent in the beginning of the conversation and upon chatbot failure to provide adequate resolution.

---

### MCT VHA Virtual Agent Research
