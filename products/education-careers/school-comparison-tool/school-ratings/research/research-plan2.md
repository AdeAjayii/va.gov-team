# Research Plan for School Ratings
As a designer I need to create a research plan to share with my team.	 	
## Goals	
1. What product & team are you doing this research for?	
- Booz Allen research for Education Services / OIT
2. Background: Briefly, what is the background on this product? What would a new person on the team need to know about this product? 	

When Veterans are looking for schools within the Comparison tool, they want to know about the experiences of other Veterans to form a better understanding of what their personal experience at the school would be like. Ratings enable Veterans to quickly assess the suitability of a school (both pro and con), bolstering their confidence and level of comfort in deciding if a particular school is right for them.

3. Research questions: What question(s) do you hope to be able to answer after completing this research? 	

- What do users think of the star ratings?
- Who do users think are providing the ratings?
- How does the number of ratings weigh into a user's perception of a particular school?
- Are users interested in the different rating categories or just the overall score?
- Which categories are valuable to users?  Are there any categories that aren't valuable?  Are there any additional categories they would like to see?
- What do users think the different categories mean?
- How do users think the rating scores are determined (average of submitted scores, calculated value, etc.)?
- Would ratings affect the school selection process?
- Do users think the ratings are useful?
- How do users think ratings are collected?
- How trustworthy are the ratings?
- What level of privacy do users expect if they would provide a rating?

4. Hypothesis: What is your hypothesis for this research? 

We believe that Veterans will understand the rating categories and find the ratings useful, especially in determining the Veteran experience at a particular school.

## Method	
1.	What method of research are you planning? 	
  - Remote moderated usability testing	
  	
2.	Why this method? How does this methodology help you answer your research questions? 	

Researchers need to be able to see how users react and interact with school ratings.  We need to be able to ask about their impressions and expectations of those ratings to determine if the current design is meeting their needs.  We also need to identify any points of confusion and whether this feature will be valuable to Veterans.

3.	Where are you planning to do your research? 

 - Online using Zoom
 
4.	What will you be testing? 
 - Prototype and content
 
5.  If remote: What tool do you plan to use (Zoom, GoToMeeting, Webex)	
 - Zoom
 
## Participants and Recruitment	
1.	Participant criteria: What are you looking for in a participant?	  
(Mention: Number of people, ages, accessibility preferences, geographical diversity, login requirements, VA benefit requirements, familiarity with technology, etc. Keep in mind, the more requirements, the more difficult the recruit, so give ample time to ensure the right participant mix.)	

Please list your participant criteria in two categories-
1. **Primary criteria / Must have** - what absolutely must be true in order to run your study? The clearer you can write this criteria, the easier it is to find matches for your study. (i.e. if your study will only work if you're talking to Veterans who have My HealtheVet premium accounts, mention that here. OR, if you are using a prototype tool that will not work well with screen readers, mention that as well.) 

2. **Secondary criteria / Would like to have** - what other criteria would strengthen your results?

*Pro tips for writing recruiting critera:* 
- If you have specific screener questions that YOU would ask a potential participant to determine eligibility for your study, list them here. For example, instead of saying "We want someone who has been to an urgent care facility recently", say "Have you been to an urgent care facility in the last 6 months? (Answer should be yes)"
- Do not assume that your recruiters or the participants know your products or requirements as well as you do. Provide links to products, clear descriptions, specifics, etc. 

2.	What is your recruitment strategy? 	
- Recruitment will be performed by Perigean Technologies	

## When? 	
1.	Timeline: What dates do you plan to do research? 	
(IF you are using the research recruiting contract, please submit 1 FULL week prior to the start of research for remote, 2+ weeks for in person.)  
* Pilot: Wed, 8/26/20. 
* Testing sessions: Thur, 8/27/20 to Fri 8/28/20.   
2.	Prepare: When will the thing you are testing be ready? (Goes without saying, but should be a few days before testing will begin.) 
* By COB: Fri, 8/20/20
3. Length of Sessions: How long do you estimate each session will be? (This helps with scheduling & thank you gifts.) e.g. 30 minutes, < 1 hour, up to 2 hours, up to 4 hours. Specify if you want Perigean to schedule the sessions with buffer time (15 minutes recommended) to allow for participants who can't make it on time, or if you might go over time.
4.	Availability: If applicable, when would you like sessions scheduled? **Please list exact dates and times in EASTERN Standard Time**. Please request enough dates and time slots (e.g. Monday 9-1, 3-6; Tuesday 9-6, etc.). Be as flexible as possible, cognizant that many Veterans are only available before and after working times, and live across the U.S.	Specify how much time you want between sessions, if any.
5.	Pilot: Please indicate a date before your sessions begin for piloting your research. Which member of the design team will you pilot your research with? 	
## Team Roles	
Please list the people who will be serving in each role. **Include the primary phone number for moderator and the emails for moderator, notetaker, and observers. If you need Perigean to take notes for you, indicate that next to Notetaker** 	
- Moderator:	Amy Knox; 301.254.0907; knox_amy@bah.com
- Research guide writing and task development (usually but not always same as moderator):	Booz Allen UX team
- Participant recruiting & screening:	Perigean Technologies
- Project point of contact:	Amy Knox
- Participant(s) for pilot test:	
- Note-takers:	Cindy Cruz cruz_cindy@bah.com; Jen Jones jones_jennifer2@bah.com
- Observers:	Brian Grubb brian.grubb@va.gov; Desiree Turner turner_desiree@bah.com; Joe Preisser joseph.preisser@va.gov; Joe Welton joseph.welton@va.gov; Will McCormack mccormack_will@bah.com; Lauren Anderson lauren.alexanderson@va.gov; Lacey Higley lacey.higley@va.gov; Matt Self matthew.self2@va.gov; Dan Shawkey shawkey_daniel@bah.com; Darla VanNieukerk darla.vannieukerk@va.gov; Tammy Hurley tammy.hurley1@va.gov; Darrell Neel neel_darrell@bah.com;Luke Tickner Lucas.Tickner@va.gov	
## Resources	
- Project Brief: 	
*Project brief should live in the appropriate va.gov-team product folder, simply paste a link to it here*	
- Convo Guide	
*Discussion guide should live in the appropriate va.gov-team product folder, simply paste a link to it here*	
- Synthesis	
*Link to any documents used for synthesis (Mural or Realtimeboard boards, excel sheets, other data outputs, etc.)* 	
- Lessons Learned	
*Did you have any takeaways from the process of this research round that you want the team to remember for the future? Document them here.* 	
- Read-Out/Results	
  - *Read-out presentation should live in the appropriate product repo and folder; paste a link to it here.* 	
  - ** Don't forget to add a link to your research folder to the research tracker! [https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/platform/research/research-history.md](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/platform/research/research-history.md)
