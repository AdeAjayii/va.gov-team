# Phase I: moderated production testing (also known as User Acceptance Testing, or UAT)

Planning:

- Desired date range or test duration: 30 days
- Desired number of users: n/a (normal monthly usage/user)
- How you'll recruit the right production test users: n/a
- How you'll conduct the testing: use of flipper feature to phase roll-out (10%, 25%, 50%, 100%)
- How you'll give the test users access to the product in production w/o making it live on VA.gov: page will be live in prod

Results:

- Number of users: 
- Number of bugs identified / fixed: 
- Types of errors logged: 
- Any UX changes necessary based on the logs, or feedback on user challenges, or VA challenges? yes/no
- If yes, what: 


# Phase II: Staged Rollout (also known as unmoderated production testing)


Planning

- Desired date range: [05/03/2021 - 05/31/2021
- How will you make the product available in production while limiting the number of users who can find/access it: [lorem ipsum]
What metrics-based criteria will you look at before advancing rollout to the next stage ("success criteria")?: [use your KPIs to help guide this. It could be things like abandonment rate < 20%, reported contact center calls < 2 calls, error rate < 5%, etc.]
Links to dashboard(s) showing "success criteria" metrics: [link here]
The stages and number of users below are provided as example values recommended by VSP, but can be customized to your team's needs.

Stage A: Canary

Test a small population of users to make sure any obvious bugs / edge cases are caught.

Planning

Length of time: x (minimum 2 hours)
Percentage of Users (and roughly how many users do you expect this to be): x% (500 users) (Recommendation: select a percentage that targets ~500 users, or at most 10%)
Results:

Number of unique users: x
Metrics at this stage (per your "success criteria"): x
Was the data submitted (if any) easy for VA to process?: yes/no, lorem ipsum
Types of errors logged: lorem ipsum
What UX changes (if any) are necessary based on the logs, or feedback on user challenges, or VA challenges?
Stage B: moderate

Test a larger population of users to make sure there are no issues exposed by larger usage patterns.

Planning

Length of time: x (minimum 1 day)
Percentage of Users (and roughly how many users do you expect this to be): 25% (x users)
Results:

Number of unique users: x
Metrics at this stage (per your "success criteria"): x
Was the data submitted (if any) easy for VA to process?: yes/no, lorem ipsum
Types of errors logged: lorem ipsum
What UX changes (if any) are necessary based on the logs, or feedback on user challenges, or VA challenges?
More stages? Sure! If it makes sense for your product! Plan them out with the same structure as above.

Go Live!

Planning:

Desired date: mm/dd/yy
Post-launch KPI 1: xx lorem ipsum
Post-launch KPI 2: xx lorem ipsum
Post-launch KPI 3: xx lorem ipsum
etc
Go / No Go: (ready / not ready)[https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/platform/product-management/go-no-go-meeting-template.md]
1-week results:

Number of unique users: x
Post-launch KPI 1 actual: xx lorem ipsum
Post-launch KPI 2 actual: xx lorem ipsum
Post-launch KPI 3 actual: xx lorem ipsum
Any issues with VA handling/processing?: yes/no, lorem ipsum
Types of errors logged: lorem ipsum
Any UX changes necessary based on the logs, or feedback on user challenges, or VA challenges? yes/no
If yes, what: lorem ipsum
1-month results:

Number of unique users: x
Post-launch KPI 1 actual: xx lorem ipsum
Post-launch KPI 2 actual: xx lorem ipsum
Post-launch KPI 3 actual: xx lorem ipsum
Any issues with VA handling/processing?: yes/no, lorem ipsum
Types of errors logged: lorem ipsum
Any UX changes necessary based on the logs, or feedback on user challenges, or VA challenges? yes/no
If yes, what: lorem ipsum
Post-launch Questions

To be completed once you have gathered your initial set of data, as outlined above.

How do the KPIs you gathered compare to your pre-launch definition(s) of "success"?
What qualitative feedback have you gathered from users or other stakeholders, if any?
Which of the assumptions you listed in your product outline were/were not validated?
How might your product evolve now or in the future based on these results?
