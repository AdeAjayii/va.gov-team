# Research Plan for Learning Center MVP

-----DRAFT--------

Liz Lantz, Public Websites, June 2020

## Goals	

1. What product & team are you doing this research for?	

   This research is for the Learning Center MVP, Public Websites team.

2. Background: Briefly, what is the background on this product? What would a new person on the team need to know about this product? 	

   When the new VA.gov was launched, a tiered content framework was created to prioritize content transition.  Tier 1 content (benefit content and tools) was brought into the VA.gov site experience first. The migration is nearly complete, and we are beginning to address migrating the tremendous amount of Tier 2, benefit-adjacent content (for beneficiaries, and people who work with beneficiaries).

   The Learning Center MVP is designed to help Veterans find Tier 2 content in a way that doesn't dilute, distract, and clutter Veterans' benefit top task content and UX.  d

3. Research questions: What question(s) do you hope to be able to answer after completing this research? 

   - Is the information easy to find using this search-focused, tag-based navigation?
   - Are the template labels (ex: FAQs, Checklist, Media List) useful to users?
   - What do users see as the difference between the learning center and overall site search?
   - Do users get confused if they don't find something in the benefit hub and they have to go to the learning center?
   - Do users understand that information they don't find in the learning center might be in the benefit hub?
   - Where would the most useful place be to provide links to the Learning Center?
   - Is the proposed IA (taxonomy, categorization, labels, nomenclature) effective for Veterans and those who support Veterans?

4. Hypothesis: What is your hypothesis for this research? 	

   - Users will easily understand how to use the search functionality.
   - Template labels will help users determine which search result is most relevant to their search.
   - Users will be unclear about when to use the Learning Center over global site search.
   -  Users won't explicitly differentiate between the benefit hub and the Learning Center; they'll default to using overall site search if they can't find what they're looking for in either place.
   - Our proposed IA will be effective for Veterans and those who support Veterans.

## Method	

1. What method of research are you planning? 	

   We're planning on doing a remote, moderated usability study to answer our first 5 questions (everything but taxonomy and labeling).  We'll ask participants to go through a clickable prototype

   To evaluate the proposed IA  (taxonomy, categorization, labels, nomenclature), we'll send out a link to a remote, unmoderated card sort.

2. Why this method? How does this methodology help you answer your research questions? 	

3. Where are you planning to do your research?

   Remotely, using Zoom	

4. What will you be testing? *(Design mocks, card sort, prototype, page, content, etc.)* 	

   We'll be testing a clickable prototype, and using a card sort through Optimal Sort.

## Participants and Recruitment	

1.	Participant criteria: What are you looking for in a participant?	
   (Mention: Number of people, ages, accessibility preferences, geographical diversity, login requirements, VA benefit requirements, familiarity with technology, etc. Keep in mind, the more requirements, the more difficult the recruit, so give ample time to ensure the right participant mix.)	
2.	What is your recruitment strategy? 	
   Recruit 50% more participants then needed, and leverage Perigean for recruiting.

## When? 	

1.	Timeline: What dates do you plan to do research? 	
   (IF you are using the research recruiting contract, please submit 1 FULL week prior to the start of research for remote, 2+ weeks for in person.) 	
2.	Prepare: When will the thing you are testing be ready? (Goes without saying, but should be a few days before testing will begin.) 	
3.	Length of Sessions: How long do you estimate each session will be? (This helps with scheduling & thank you gifts.) e.g. 30 minutes, < 1 hour, up to 2 hours, up to 4 hours) 	
4.	Availability: If applicable, when would you like sessions scheduled? **Please list exact dates and times in EASTERN Standard Time**. Please request enough dates and time slots (e.g. Monday 9-1, 3-6; Tuesday 9-6, etc.). Be as flexible as possible, cognizant that many Veterans are only available before and after working times, and live across the U.S.	
5.	Pilot: Please indicate a date before your sessions begin for piloting your research. Which member of the design team will you pilot your research with? 	

## Team Roles	

Please list the people who will be serving in each role. **Include the primary phone number for moderator and the emails for moderator, notetaker, and observers. If you need Perigean to take notes for you, indicate that next to Notetaker** 	

- Moderator: Liz Lantz, 843-898-4463, liz.lantz@adhocteam.us

- Research guide writing and task development (usually but not always same as moderator): Liz Lantz

- Participant recruiting & screening: Perigean 

- Project point of contact: Liz Lantz

- Participant(s) for pilot test:	

- Note-takers:	

- Observers:	

  - Jen Lee (jennifer.lee27@va.gov)

  - Ryan Thurlwell (Ryan.Thurlwell@va.gov)

  - Danielle Thierry (danielle.thierry@va.gov)

  - Beth Potts (beth.potts@va.gov)

  - John Hashimoto ()

  - Kelson Adams ()

  - Oksana Cyrwus

  - Kevin Walsh

  - Laura Walsh

  - Nick Sullivan (nick.sullivan@adhoc.team)

  - Randi Hecht

  - Mikki Northuis

  - Selina Cooper

  - Anne Hurley

  - Steve Wirt

    

## Resources	

- [Product Outline](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/content/tier-2-content-IA-and-design/learning-center-mvp/product-outline.md) 
- Convo Guide - coming soon
- Prototype to be tested - coming soon
- Card sort - coming soon
- Synthesis - coming soon
- Lessons Learned - coming soon	
- Read-Out/Results  - coming soon
