# Chatbot Controlled Study Research Report (DRAFT)

#### Shane Strassberg and Rachel M. Murray, [research plan](https://github.com/department-of-veterans-affairs/va.gov-team/blob/master/products/virtual-agent/research/controlled-study/controlled-study-research-plan.md)

## Introduction

A well-developed and maintained virtual agent will help users solve problems and complete tasks on their own with little to no human involvement at any time of day. Ultimately, the problem we want to solve with our virtual agent is to help the Veteran self-serve and find information more easily as part of a larger Omnichannel strategy (led by VEO) to provide veterans with seamless access to information.  Because of the amount of content that is available and needs to be rewritten in conversational format for the chatbot, we want to target starting with smaller targeted content. A proof of value (POV) was created with a preliminary set of features and content; this report details the feedback on that product.


## Research Goals

We established a number of goals around the product and how people used it. There are many ways of understanding the success of a product, but for this research study we wanted to learn how the chatbot performed and how it was ‘seen’ as being able to perform, since accuracy shapes how people trust a product. We also wanted to examine trust as tied to how personality can reinforce trust, and how all of these affected the larger brand relationship participants have with the VA support channels - the ultimate goal to understand if participants would use the chatbot again.

The goals of this study included:

- A: Accuracy: 
  - Understand how well the chatbot performed (answered questions accurately, understood what participants were trying to ask, and if participants had information needed to take the next step to complete a task
  - Understand if and how poor performance affected participants

- B: Trust:
  - Understand if people preferred to sign in (get answers to personal questions) or not to sign in (even if it means no personalized answers) and if they trusted the chatbot

- C: Personality:
  - Understand how participants felt about the voice and tone of the chatbot

- D: Product usage:
  - Understand how often participants speak with a VA help desk/contact center, reasons why and how a chatbot can reduce how often they call the VA
Understand if participants are willing to use the chatbot again

## Research Methodology

We launched with an unmoderated controlled study of 50 participants and were able to recruit 46 in total.  Participants were invited by Perigean to participate in the research study by email and have a number of research repositories that captured the data. 

- Participants were sent a link to the chatbot on Staging.va.gov and were able to engage with it. These are the ‘chatbot log transcripts’ which are reflected in the Metrics, and show the types of questions and interactions with the product.
- Participants were also sent a link to a questionnaire on Optimal Workshop. This included both quantitative questions where people were asked to rate their opinion from a preselected set of options, and qualitative questions where people were asked to provide written feedback.

## Hypotheses 

TBD

We identified a set of hypotheses we wanted to validate or refute using data which were tied to our goals

- A: Accuracy:
  - We will see a high number of questions that the bot has not yet been trained to answer. 
  - Veterans will expect that the chatbot cannot answer in-depth questions. 

- B: Trust:
  - More Veterans will attempt to find information that requires authentication (e.g., claims-status). 
  - Veterans who may be seeking anonymity (e.g., LGBTQ+, housing or food insecurity, mental-health crisis) may be more comfortable utilizing this tool over speaking with a human.

- C: Personality:
  - Veterans will want a more professional tone than a more ‘friendly’ personable tone.


(more to come)



## Participants

* Role
   * x Veterans
   * x Veteran family or caregivers
* Gender: 
   *  women
   *  men
* Geographically diverse: 
   *  
* Age range
   *  participant  25-34
   *  participants 35 - 44
   *  participants 45 - 54
   *  participant 55-65
   *  participant over 65
   *  participant no age stated


Group | Segment and number of participants
------------ | -------------
Veterans | Segment #1: 10 participants who are female Veterans across age brackets and conflicts/periods of service - Korean Conflict, Vietnam Era, Persian Gulf, Afghanistan, Iraq.  We were able to recruit 10 out of 10 of this segment.
Veterans | Segment #2: 10 participants who are male Veterans  across age brackets and conflicts/periods of service - Korean Conflict, Vietnam Era, Persian Gulf, Afghanistan, Iraq.  We were able to recruit 9 out of 10 of this segment.
Non-Veteran | Segment #3: 10 participants who are people close to Veterans - female caretakers, male caretakers or family members (i.e. dependents).  We were able to recruit 7 out of 10 of this segment.
Usage related | Segment #4: 10 participants who are new to va.gov (2 years or less)  We were able to recruit 3 out of 10 of this segment.
Usage related | Segment #5: 10 participants who are casual, infrequent users of va.gov (once a year).  We were able to recruit 8 out of 10 of this segment.
Usage related | Segment #6: 10 participants who are frequent users (dependent on claims etc. or who visit va.gov daily or weekly). We were able to recruit 7 out of 10 of this segment.
Location | Segment #7: 10 participants who live in urban centers. We were able to recruit 1 out of 10 of this segment.
Location | Segment #8: 10 participants who live in suburban or rural areas.  We were unable to recruit for this segment.
Marginalized populations | Segment #9: 10 participants who identify as LGBTQ+.  We were able to recruit 1 out of 10 of this segment.
Marginalized populations| Segment #10: 10 participants who are experiencing economic insecurity - (i.e. experiencing homelessness/housing insecure, food insecurity, either currently or previously in their time as a Veteran post-discharge from service). We were unable to recruit for this segment.

## Key Findings


1. Point
* list
   * indented


## Details of Findings

TBD

## Metrics

TBD  (table)

## Additional Insights

TBD


## Future research areas

TBD


## Next Steps

* TBD


## Appendix

### Conversation guide
n/a

### Interview transcripts
n/a

### Pages and applications used
Pages tested: https://staging.va.gov/virtual-agent-study/ 


